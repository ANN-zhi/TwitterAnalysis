{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Times to Tweets in Healthcare vs. Education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"E:\\OneDrive - University of Georgia\\Project\\Data\\tweet_data_2_food\\4.3 FourColumns 3+1csv\\fastFood_2019.csv\",low_memory=False)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the \"Created At\" field into a datetime data type, extract the day of the week, and map it onto a new column called \"weekdays\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "df1 = df.copy()\n",
    "\n",
    "df1['local_time'] = pd.to_datetime(df1['local_time'])\n",
    "value = df1['local_time']\n",
    "        \n",
    "def weekday(date):\n",
    "    if date.weekday() == 0:\n",
    "        return 'Monday'\n",
    "    elif date.weekday() == 1:\n",
    "        return 'Tuesday'\n",
    "    elif date.weekday() == 2:\n",
    "        return 'Wednesday'\n",
    "    elif date.weekday() == 3:\n",
    "        return 'Thursday'\n",
    "    elif date.weekday() == 4:\n",
    "        return 'Friday'\n",
    "    elif date.weekday() == 5:\n",
    "        return 'Saturday'\n",
    "    else:\n",
    "        return 'Sunday'\n",
    "\n",
    "df1[\"weekdays\"] = value.map(weekday)\n",
    "df1['weekdays']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the time and map it onto a new column called \"time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "\n",
    "def time(date):\n",
    "    time2 = date.time()\n",
    "    return time2\n",
    "\n",
    "df2[\"time\"] = value.map(time)\n",
    "df2['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group the times into hourly buckets and map it onto a new column called \"time groups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()\n",
    "\n",
    "def time_groups(time):\n",
    "    if time >= datetime.time(0,0) and time <= datetime.time(1,0):\n",
    "        return '12AM-1AM'\n",
    "    elif time >= datetime.time(1,0) and time <= datetime.time(2,0):\n",
    "        return '1AM-2AM'\n",
    "    elif time >= datetime.time(2,0) and time <= datetime.time(3,0):\n",
    "        return '2AM-3AM'\n",
    "    elif time >= datetime.time(3,0) and time <= datetime.time(4,0):\n",
    "        return '3AM-4AM'\n",
    "    elif time >= datetime.time(4,0) and time <= datetime.time(5,0):\n",
    "        return '4AM-5AM'\n",
    "    elif time >= datetime.time(5,0) and time <= datetime.time(6,0):\n",
    "        return '5AM-6AM'\n",
    "    elif time >= datetime.time(6,0) and time <= datetime.time(7,0):\n",
    "        return '6AM-7AM'\n",
    "    elif time >= datetime.time(7,0) and time <= datetime.time(8,0):\n",
    "        return '7AM-8AM'\n",
    "    elif time >= datetime.time(8,0) and time <= datetime.time(9,0):\n",
    "        return '8AM-9AM'\n",
    "    elif time >= datetime.time(9,0) and time <= datetime.time(10,0):\n",
    "        return '9AM-10AM'\n",
    "    elif time >= datetime.time(10,0) and time <= datetime.time(11,0):\n",
    "        return '10AM-11AM'\n",
    "    elif time >= datetime.time(11,0) and time <= datetime.time(12,0):\n",
    "        return '11AM-12PM'\n",
    "    elif time >= datetime.time(12,0) and time <= datetime.time(13,0):\n",
    "        return '12PM-1PM'\n",
    "    elif time >= datetime.time(13,0) and time <= datetime.time(14,0):\n",
    "        return '1PM-2PM'\n",
    "    elif time >= datetime.time(14,0) and time <= datetime.time(15,0):\n",
    "        return '2PM-3PM'\n",
    "    elif time >= datetime.time(15,0) and time <= datetime.time(16,0):\n",
    "        return '3PM-4PM'\n",
    "    elif time >= datetime.time(16,0) and time <= datetime.time(17,0):\n",
    "        return '4PM-5PM'\n",
    "    elif time >= datetime.time(17,0) and time <= datetime.time(18,0):\n",
    "        return '5PM-6PM'\n",
    "    elif time >= datetime.time(18,0) and time <= datetime.time(19,0):\n",
    "        return '6PM-7PM'\n",
    "    elif time >= datetime.time(19,0) and time <= datetime.time(20,0):\n",
    "        return '7PM-8PM'\n",
    "    elif time >= datetime.time(20,0) and time <= datetime.time(21,0):\n",
    "        return '8PM-9PM'\n",
    "    elif time >= datetime.time(21,0) and time <= datetime.time(22,0):\n",
    "        return '9PM-10PM'\n",
    "    elif time >= datetime.time(22,0) and time <= datetime.time(23,0):\n",
    "        return '10PM-11PM'\n",
    "    elif time >= datetime.time(23,0) and time <= datetime.time(23,59):\n",
    "        return '11PM-12AM'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "df3[\"time groups\"] = df3['time'].map(time_groups)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the value counts of \"weekdays\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['weekdays'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the value counts of \"time groups\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3['time groups'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renamed \"time groups\" to \"time_groups\" for manipulation purposes later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "df5 = df4.rename(index=str, columns={\"time groups\": \"time_groups\"})\n",
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the efficiency scores for the heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#quantile \n",
    "import numpy as np\n",
    "\n",
    "data=[1695, 1045, 552, 386, 406, 736, 1493, 2652, 3928, 4266, 4649, 5297, 5970, 5690, 5403, 5147, 5045, 5434, 5541, 5446, 5427, 5117, 4251, 2959,1906, 1104, 628, 369, 400, 823, 1667, 3245, 4535, 4878, 5015, 5497, 6280, 5854, 5348, 5273, 5117, 5370, 5433, 5279, 5154, 4798, 4099, 2973,1981, 1130, 595, 408, 405, 760, 1701, 3105, 4688, 5077, 5117, 5618, 6019, 6065, 5524, 5180, 4845, 5334, 5479, 5267, 5200, 4972, 4256, 3043,2030, 1143, 744, 443, 421, 811, 1812, 3407, 4928, 5482, 5471, 5943, 6409, 5993, 5527, 5431, 5231, 5421, 5595, 5246, 5033, 4903, 4064, 3038,2015, 1184, 764, 472, 414, 780, 1861, 3437, 5010, 5203, 5232, 5412, 6272, 5969, 5232, 4853, 4678, 4508, 4879, 4687, 4260, 4056, 3615, 2789,2097, 1431, 967, 562, 437, 568, 995, 1960, 3300, 4431, 5026, 5122, 5411, 5178, 4957, 4497, 4454, 4397, 4373, 4130, 4224, 3941, 3481, 2881,2276, 1617, 1043, 665, 462, 486, 870, 1570, 2561, 3450, 4278, 4710, 5084, 4899, 4560, 4411, 4143, 4120, 4302, 4356, 4448, 4207, 3389, 2500]\n",
    "quartile_1 = np.quantile(data, 0.0625)\n",
    "quartile_2 = np.quantile(data, 0.125)\n",
    "quartile_3 = np.quantile(data, 0.1875)\n",
    "quartile_4 = np.quantile(data, 0.25)\n",
    "quartile_5 = np.quantile(data, 0.3125)\n",
    "quartile_6 = np.quantile(data, 0.375)\n",
    "quartile_7 = np.quantile(data, 0.4325)\n",
    "quartile_8 = np.quantile(data, 0.5)\n",
    "quartile_9 = np.quantile(data, 0.5625)\n",
    "quartile_10 = np.quantile(data, 0.625)\n",
    "quartile_11 = np.quantile(data, 0.6875)\n",
    "quartile_12 = np.quantile(data, 0.75)\n",
    "quartile_13 = np.quantile(data, 0.8125)\n",
    "quartile_14 = np.quantile(data, 0.875)\n",
    "quartile_15 = np.quantile(data, 0.9325)\n",
    "quartile_16 = np.quantile(data, 1)\n",
    "\n",
    " \n",
    "print(quartile_1,\n",
    "      quartile_2,\n",
    "      quartile_3,\n",
    "      quartile_4,\n",
    "      quartile_5,\n",
    "      quartile_6,\n",
    "      quartile_7,\n",
    "      quartile_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "days_of_week = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \n",
    "                \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "time_frames = [\"12AM-1AM\", \"1AM-2AM\", \"2AM-3AM\", \"3AM-4AM\", \"4AM-5AM\", \n",
    "               \"5AM-6AM\", \"6AM-7AM\", \"7AM-8AM\", \"8AM-9AM\", \"9AM-10AM\",\n",
    "               \"10AM-11AM\", \"11AM-12PM\", \"12PM-1PM\", \"1PM-2PM\", \"2PM-3PM\",\n",
    "               \"3PM-4PM\", \"4PM-5PM\", \"5PM-6PM\", \"6PM-7PM\", \"7PM-8PM\",\n",
    "               \"8PM-9PM\", \"9PM-10PM\", \"10PM-11PM\", \"11PM-12AM\"]\n",
    "\n",
    "\n",
    "def hc_efficiency_score(df, day, times):\n",
    "    array1 = []\n",
    "    array2=[]\n",
    "    instance_val = 0\n",
    "    #for each of the time frames\n",
    "    for time in times:\n",
    "        #locate the day of the week and the specific time frame, pull the data\n",
    "        m1 = df.loc[(df[\"weekdays\"]== day) & (df[\"time_groups\"]== time),\n",
    "                 [\"weekdays\", \"time_groups\"]]\n",
    "        #If there are no tweets in that time frame\n",
    "        if m1[\"time_groups\"].count() == 0:\n",
    "            #instance_val = 0\n",
    "            #lowest category\n",
    "            sum1 = 0\n",
    "        else:\n",
    "            #Sum the retweets, replies, and favorites and divide by num of tweets\n",
    "            instance_val =  m1[\"time_groups\"].count()\n",
    "            array2.append(instance_val)\n",
    "            #758.0 1784.25 3355.625 4290.0 4878.375 5185.0 5435.5 6409\n",
    "            #putting the tweets into categorical buckets\n",
    "            if  instance_val >=  quartile_15 and instance_val <quartile_16+1:\n",
    "                sum1 = 16\n",
    "            elif instance_val >= quartile_14 and instance_val < quartile_15:\n",
    "                sum1 = 15\n",
    "            elif  instance_val >=  quartile_13 and instance_val <quartile_14:\n",
    "                sum1 = 14\n",
    "            elif instance_val >= quartile_12 and instance_val < quartile_13:\n",
    "                sum1 = 13\n",
    "            elif instance_val >= quartile_11 and instance_val < quartile_12:\n",
    "                sum1 = 12\n",
    "            elif instance_val >= quartile_10 and instance_val < quartile_11:\n",
    "                sum1 = 11\n",
    "            elif instance_val >= quartile_9 and instance_val < quartile_10:\n",
    "                sum1 = 10\n",
    "            elif instance_val >=  quartile_8 and instance_val <quartile_9:\n",
    "                sum1 = 9\n",
    "            elif instance_val >= quartile_7 and instance_val <quartile_8:\n",
    "                sum1 = 8\n",
    "            elif instance_val >= quartile_6 and instance_val < quartile_7:\n",
    "                sum1 = 7\n",
    "            elif instance_val >= quartile_5 and instance_val < quartile_6:\n",
    "                sum1 = 6\n",
    "            elif instance_val >= quartile_4 and instance_val < quartile_5:\n",
    "                sum1 = 5\n",
    "            elif instance_val >= quartile_3 and instance_val < quartile_4:\n",
    "                sum1 = 4\n",
    "            elif instance_val >=  quartile_2 and instance_val <quartile_3:\n",
    "                sum1 = 3\n",
    "            elif instance_val >= quartile_1 and instance_val <quartile_2:\n",
    "                sum1 = 2\n",
    "            else:\n",
    "                sum1 = 1\n",
    "        \n",
    "        array1.append(sum1)\n",
    "        \n",
    "    #print(array2)\n",
    "    return array1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat map for Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_score = []\n",
    "\n",
    "m_array = hc_efficiency_score(df5, \"Monday\", time_frames)\n",
    "tweet_score.append(m_array)\n",
    "t_array = hc_efficiency_score(df5, \"Tuesday\", time_frames)\n",
    "tweet_score.append(t_array)\n",
    "w_array = hc_efficiency_score(df5, \"Wednesday\", time_frames)\n",
    "tweet_score.append(w_array)\n",
    "th_array = hc_efficiency_score(df5, \"Thursday\", time_frames)\n",
    "tweet_score.append(th_array)\n",
    "f_array = hc_efficiency_score(df5, \"Friday\", time_frames)\n",
    "tweet_score.append(f_array)\n",
    "st_array = hc_efficiency_score(df5, \"Saturday\", time_frames)\n",
    "tweet_score.append(st_array)\n",
    "s_array = hc_efficiency_score(df5, \"Sunday\", time_frames)\n",
    "tweet_score.append(s_array)\n",
    "print(tweet_score)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,50))\n",
    "#(figsize=(width,height))\n",
    "im = ax.imshow(tweet_score, cmap = cm.Blues)\n",
    "\n",
    "#get rid of grid lines\n",
    "ax.grid(False)\n",
    "\n",
    "#show all ticks...\n",
    "ax.set_xticks(np.arange(len(time_frames)))\n",
    "ax.set_yticks(np.arange(len(days_of_week)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels(time_frames, fontsize=20)\n",
    "ax.set_yticklabels(days_of_week, fontsize=20)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "cbarlabel = \"Frecuency Score\"\n",
    "\n",
    "cbar = ax.figure.colorbar(im, ax=ax,shrink=0.07)\n",
    "\n",
    "cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\", fontsize = 20)\n",
    "\n",
    "ax.set_title(\"fastfood 2019\", fontsize = 30)\n",
    "fig.tight_layout()\n",
    "#plt.show()\n",
    "from PIL import Image\n",
    "#plt.savefig(\"time_grid_2019.jpg\",dpi=1000,pad_inches=0,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"time_grid_fastfood_2019.jpg\",dpi=1200,pad_inches=0,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many tweets in each timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_count = []\n",
    "\n",
    "def tweets(df, day, times):\n",
    "    array1 = []\n",
    "    for time in times:\n",
    "        m1 = df.loc[(df[\"weekdays\"]== day) & (df[\"time_groups\"]== time),\n",
    "                 [\"weekdays\",\"time_groups\"]]\n",
    "        instance_val = m1[\"time_groups\"].count()\n",
    "        array1.append(instance_val)\n",
    "    return array1\n",
    "\n",
    "m_count = tweets(df5, \"Monday\", time_frames)\n",
    "print(\"Monday: \", m_count)\n",
    "tweet_count.append(m_count)\n",
    "t_count = tweets(df5, \"Tuesday\", time_frames)\n",
    "tweet_count.append(t_count)\n",
    "print(\"Tuesday: \", t_count)\n",
    "w_count = tweets(df5, \"Wednesday\", time_frames)\n",
    "tweet_count.append(w_count)\n",
    "print(\"Wednesday: \", w_count)\n",
    "th_count = tweets(df5, \"Thursday\", time_frames)\n",
    "tweet_count.append(th_count)\n",
    "print(\"Thursday: \", th_count)\n",
    "f_count = tweets(df5, \"Friday\", time_frames)\n",
    "tweet_count.append(f_count)\n",
    "print(\"Friday: \", f_count)\n",
    "st_count = tweets(df5, \"Saturday\", time_frames)\n",
    "tweet_count.append(st_count)\n",
    "print(\"Saturday: \", st_count)\n",
    "s_count = tweets(df5, \"Sunday\", time_frames)\n",
    "tweet_count.append(s_count)\n",
    "print(\"Sunday: \", s_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
