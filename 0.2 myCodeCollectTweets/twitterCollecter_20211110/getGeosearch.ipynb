{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b6f9e0",
   "metadata": {},
   "source": [
    "# Collecting tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab82265",
   "metadata": {},
   "source": [
    "update: import the start_date_end_date.py to add parameters of start and end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5308b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For dealing with json responses we receive from the API\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import tweepy\n",
    "\n",
    "import auth_function\n",
    "import create_url_function\n",
    "import connect_to_endpoint_function\n",
    "import append_to_csv_function\n",
    "import start_date_end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5452e07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Token:  None\n",
      "Endpoint Response Code: 200\n",
      "Next Token:  b26v89c19zqg8o3fo77fgky8fjbps7zbm68n1vka86oal\n",
      "Start Date:  2020-03-01T00:00:00.000Z\n",
      "# of Tweets added from this response:  479\n",
      "Total # of Tweets added:  479\n",
      "-------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cc3a74d4ff78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total # of Tweets added: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_tweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-------------------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;31m# If no next token exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Inputs for tweets\n",
    "bearer_token = auth_function.auth()\n",
    "headers = auth_function.create_headers(bearer_token)\n",
    "keyword = \"(obesity) OR (overweight) OR (fat)OR (heavy)OR (heavier)OR (weight)OR (fatter)OR (adipose)OR (belly)OR (bmi) OR (obese)OR (diet)OR (diets)OR(calories)OR(overeating) lang:en place_country:US\"\n",
    "start_list = start_date_end_date.start_list          \n",
    "end_list = start_date_end_date.end_list\n",
    "max_results = 10\n",
    "\n",
    "#Total number of tweets we collected from the loop\n",
    "total_tweets = 0\n",
    "\n",
    "# Create file\n",
    "csvFile = open(\"data.csv\", \"a\", newline=\"\", encoding='utf-8')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "\n",
    "#Create headers for the data you want to save, in this example, we only want save these columns in our dataset\n",
    "csvWriter.writerow(['author id', 'created_at', 'geo', 'id','lang', 'like_count', 'quote_count', 'reply_count','retweet_count','source','tweet'])\n",
    "csvFile.close()\n",
    "\n",
    "for i in range(0,len(start_list)):\n",
    "\n",
    "    # Inputs\n",
    "    count = 0 # Counting tweets per time period\n",
    "    max_count = 100 # Max tweets per time period\n",
    "    flag = True\n",
    "    next_token = None\n",
    "    \n",
    "    # Check if flag is true\n",
    "    while flag:\n",
    "        # Check if max_count reached\n",
    "        if count >= max_count:\n",
    "            break\n",
    "        print(\"-------------------\")\n",
    "        print(\"Token: \", next_token)\n",
    "        url = create_url_function.create_url(keyword, start_list[i],end_list[i], max_results)\n",
    "        json_response = connect_to_endpoint_function.connect_to_endpoint(url[0], headers, url[1], next_token)\n",
    "        result_count = json_response['meta']['result_count']\n",
    "\n",
    "        if 'next_token' in json_response['meta']:\n",
    "            # Save the token to use for next call\n",
    "            next_token = json_response['meta']['next_token']\n",
    "            print(\"Next Token: \", next_token)\n",
    "            if result_count is not None and result_count > 0 and next_token is not None:\n",
    "                print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv_function.append_data_to_csv(json_response, \"data.csv\")\n",
    "                append_to_csv_function.append_includes_to_csv(json_response, \"includes.csv\")\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)                \n",
    "        # If no next token exists\n",
    "        else:\n",
    "            if result_count is not None and result_count > 0:\n",
    "                print(\"-------------------\")\n",
    "                print(\"Start Date: \", start_list[i])\n",
    "                append_to_csv_function.append_data_to_csv(json_response, \"data.csv\")\n",
    "                append_to_csv_function.append_includes_to_csv(json_response, \"includes.csv\")\n",
    "                count += result_count\n",
    "                total_tweets += result_count\n",
    "                print(\"Total # of Tweets added: \", total_tweets)\n",
    "                print(\"-------------------\")\n",
    "                time.sleep(5)\n",
    "            \n",
    "            #Since this is the final request, turn flag to false to move to the next time period.\n",
    "            flag = False\n",
    "            next_token = None\n",
    "        time.sleep(5)\n",
    "print(\"Total number of results: \", total_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ea8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf29a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(pandemic) OR (COVID-19) OR (coronavirus)OR (COVID)OR (lockdown)OR (home confinement)OR (stay-at-home)OR (quarantine)OR (isolation)OR ()\n",
    "\n",
    "walk out??\n",
    "(obesity) OR (overweight) OR (fat)OR (heavy)OR (heavier)OR (weight)OR (fatter)OR (adipose)OR (belly)OR ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83278d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
